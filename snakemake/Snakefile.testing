import json
from math import *
from os.path import join
import subprocess

include: "Snakefile"


#-----------------------------------------------------------------------------
# BEGIN functions
#-----------------------------------------------------------------------------

def check_batch_range(wildcards):
    return batch_range(wildcards, config["check_batch_size"], get_num_contigs(reference))


def __get_check_batches(file_template):
    workdir_ = config["workdir"]
    num_contigs = get_num_contigs(reference)
    num_batches = ceildiv(num_contigs, config["check_batch_size"])
    num_digits = int(ceil(log10(num_batches)))
    batch_id_format = "{{:0{}d}}".format(num_digits)

    def get_check_batch(batch_id):
        workdir_ = config["workdir"]
        check_batch = file_template
        batch_id = batch_id_format.format(batch_id)

        return join(workdir_, check_batch.format(batch_id=batch_id))

    return (get_check_batch(i)  for i in range(num_batches))


def result_stats_batches():
    return __get_check_batches(config["workflow"]["result_stats_batch"])


def gap_details_batches():
    return __get_check_batches(config["workflow"]["gap_details_batch"])

#-----------------------------------------------------------------------------
# END functions
#-----------------------------------------------------------------------------


#-----------------------------------------------------------------------------
# Variables for rules
#-----------------------------------------------------------------------------

# config shortcuts
testing_inputs = config["inputs"]

# workflow files
ground_trouth = testing_inputs["ground_trouth"]
short_read_assembly = testing_inputs["short_read_assembly"]
short_vs_true_alignment = alignment_file(ground_trouth, short_read_assembly)
contig_mapping = testing_inputs["contig_mapping"]
result_db = fasta_to_workdb(output_assembly, "dam")
testing_config_file = prepend_ext(dentist_config_file, ".testing")

result_stats = config["result_stats"]
result_stats_batch = join(workdir_, workflow_["result_stats_batch"])
gap_details = config["gap_details"]
gap_details_batch = join(workdir_, workflow_["gap_details_batch"])

#-----------------------------------------------------------------------------
# BEGIN rules
#-----------------------------------------------------------------------------


localrules:
    extend_dentist_config_for_testing,
    short_vs_true_alignment,
    result2dam,
    merge_result_stats,
    merge_gap_details,
    check


rule extend_dentist_config_for_testing:
    input: dentist_config_file
    output: testing_config_file
    run:
        dentist_config = None
        with open(dentist_config_file, 'r') as base_config:
            dentist_config = json.load(base_config)

        if "__default__" not in dentist_config:
            dentist_config["__default__"] = dict()
        dentist_config["__default__"]["true-assembly"] = ground_trouth
        dentist_config["__default__"]["short-read-assembly"] = short_read_assembly
        dentist_config["__default__"]["short-vs-true-alignment"] = short_vs_true_alignment
        dentist_config["__default__"]["mapped-regions-mask"] = contig_mapping
        dentist_config["__default__"]["test-assembly"] = reference_fasta
        dentist_config["__default__"]["result"] = result_db

        if "check-results" not in dentist_config:
            dentist_config["check-results"] = dict()
        dentist_config["check-results"]["json"] = True
        dentist_config["check-results"]["bucket-size"] = 0

        with open(output[0], 'w') as ext_config_file:
            json.dump(dentist_config, ext_config_file)

        validate_dentist_config(output[0])


rule short_vs_true_alignment_block:
    input:
        db_files(ground_trouth),
        db_files(short_read_assembly)
    output: temp(alignment_file(ground_trouth, short_read_assembly, block_a='{block_true}', block_b='{block_short}'))
    params:
        aligncmd = generate_options_for("short vs true assembly"),
        true_stub = db_stub(rel_to_workdir(ground_trouth)),
        short_stub = db_stub(rel_to_workdir(short_read_assembly)),
        dalign_flags = prepare_flags(dalign_flags)
    threads: max_threads
    shell:
        "cd {workdir_} && {params.aligncmd} {params.dalign_flags} {params.true_stub}.{wildcards.block_true} {params.short_stub}.{wildcards.block_short}"


rule short_vs_true_alignment:
    input:
        db_files(ground_trouth),
        db_files(short_read_assembly),
        block_alignments = block_alignments(ground_trouth, short_read_assembly)
    output:
        short_vs_true_alignment
    shell:
        "LAmerge {output} {input[block_alignments]}"


rule translocate:
    input:
        testing_config_file,
        db_files(ground_trouth),
        db_files(short_read_assembly),
        short_vs_true_alignment
    output:
        reference_fasta
    log: log_file("translocate")
    shell:
        "dentist translocate --config={testing_config_file} - - - - - 2> {log}"


_fast2dam_checkpoint[result_db] = "result2dam"
checkpoint result2dam:
    input: output_assembly
    output: *db_files(result_db)
    shell:
        "fasta2DAM {output[0]} {input} && DBsplit {dbsplit_flags} {output[0]}"


rule check_batch:
    input:
        testing_config_file,
        db_files(ground_trouth),
        mask_files(ground_trouth, contig_mapping),
        db_files(reference),
        await_db_files(result_db)
    output:
        result_stats = temp(result_stats_batch),
        gap_details = temp(gap_details_batch)
    params:
        batch_range = check_batch_range,
        main_threads = main_threads,
        auxiliary_threads = auxiliary_threads
    threads: max_threads
    log: log_file("check.{batch_id}")
    shell:
        "dentist check --config={testing_config_file} --threads={params.main_threads} --auxiliary-threads={params.auxiliary_threads} --batch={params.batch_range} --gap-details={output[gap_details]} - - - - 2> {log} > {output[result_stats]}"


rule merge_result_stats:
    input:
        await_db_files(result_db),
        result_stats_batches = lambda _: result_stats_batches(),
    output:
        protected(result_stats),
    threads: max_threads
    shell:
        "jq -sc add {input[result_stats_batches]} > {output}"


rule merge_gap_details:
    input:
        await_db_files(result_db),
        gap_details_batches = lambda _: gap_details_batches(),
    output:
        protected(gap_details),
    threads: max_threads
    shell:
        "cat {input[gap_details_batches]} > {output}"


rule check:
    input:
        result_stats,
        gap_details

#-----------------------------------------------------------------------------
# END rules
#-----------------------------------------------------------------------------
